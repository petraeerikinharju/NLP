{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\OMISTAJA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Duplicate Module doesn't exist\n",
      "WARNING:tensorflow:From c:\\Users\\OMISTAJA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\OMISTAJA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\OMISTAJA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\OMISTAJA\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import spacy\n",
    "import numpy as np\n",
    "import tensorflow_hub as hub\n",
    "import os\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.stats import pearsonr\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from SOC_PMI.main import similarity\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
    "embed = hub.load(module_url)\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "distilbert_model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "stopwords = list(set(nltk.corpus.stopwords.words('english')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TASK 1 ###\n",
    "\n",
    "def preProcess(sentence):\n",
    "    \"\"\"Preprocess a single sentence by tokenizing, converting to lowercase, and removing stop words.\"\"\"\n",
    "    tokenized_sentence = nltk.word_tokenize(sentence.lower())\n",
    "    filtered_sentence = [word for word in tokenized_sentence if word not in stopwords]\n",
    "    return filtered_sentence\n",
    "\n",
    "\n",
    "def sim1(sentence_list):\n",
    "    \"\"\"Calculate sentence-to-sentence similarity using TF-IDF and WordNet similarity.\"\"\"\n",
    "    computed_similarities = []\n",
    "    tf = TfidfVectorizer(use_idf=True)\n",
    "\n",
    "    for T1, T2 in sentence_list:\n",
    "        words1 = preProcess(T1)\n",
    "        words2 = preProcess(T2)\n",
    "\n",
    "        tf_matrix = tf.fit_transform([' '.join(words1), ' '.join(words2)])\n",
    "        \n",
    "        sim_score = cosine_similarity(tf_matrix[0:1], tf_matrix[1:2])[0][0]\n",
    "        computed_similarities.append(round(sim_score, 2))\n",
    "\n",
    "    return computed_similarities\n",
    "\n",
    "def read_from_csv(file_path):\n",
    "    \"\"\"Read sentences and the corresponding similarity scores from a csv file using pandas.\"\"\"\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(file_path, delimiter=';', encoding='utf-8')\n",
    "    \n",
    "    # Ensure the DataFrame has the correct number of columns\n",
    "    if df.shape[1] != 3:\n",
    "        raise ValueError(\"CSV file must contain exactly 3 columns.\")\n",
    "\n",
    "    # Extract sentences and scores\n",
    "    sentences = list(zip(df.iloc[:, 0].str.strip(), df.iloc[:, 1].str.strip()))\n",
    "    scores = df.iloc[:, 2].astype(float).tolist()\n",
    "    \n",
    "    return sentences, scores\n",
    "\n",
    "### TASK 2 ###\n",
    "\n",
    "def antonym(token):\n",
    "    \"\"\"Return the antonym of a given token using WordNet.\"\"\"\n",
    "    synsets = wn.synsets(token)\n",
    "    for syn in synsets:\n",
    "        for lemma in syn.lemmas():\n",
    "            if lemma.antonyms():\n",
    "                return lemma.antonyms()[0].name()  # Return the first antonym found\n",
    "    return token  # Return the original token if no antonym is found\n",
    "\n",
    "def preprocess_with_negation_and_entities(sentence):\n",
    "    \"\"\"Preprocess a sentence to handle negation and extract noun entities.\"\"\"\n",
    "    doc = nlp(sentence)\n",
    "    tokens = [token for token in doc]  # Keep token objects\n",
    "    \n",
    "    # Check for named entities\n",
    "    named_entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    if len(named_entities) == 0:  # No named entities\n",
    "        negated_tokens = []\n",
    "        for i, token in enumerate(tokens):\n",
    "            if token.text.lower() in ['not', 'no', 'never']:  # Negation found\n",
    "                if i + 1 < len(tokens) and tokens[i + 1].pos_ in ['ADJ', 'ADV']:\n",
    "                    negated_tokens.append(antonym(tokens[i + 1].text))  # Convert to antonym\n",
    "                else:\n",
    "                    negated_tokens.append(token.text)  # Keep the negation\n",
    "            else:\n",
    "                negated_tokens.append(token.text)\n",
    "\n",
    "        # Filter to nouns and convert to nouns using WordNet\n",
    "        noun_tokens = []\n",
    "        for token in negated_tokens:\n",
    "            pos = wn.synsets(token)\n",
    "            if pos:  # If token exists in WordNet\n",
    "                noun_tokens.append(pos[0].lemmas()[0].name())  # Convert to noun\n",
    "\n",
    "        return [nt for nt in noun_tokens if nt not in stopwords], named_entities\n",
    "\n",
    "    else:  # Handle named entities\n",
    "        # Discard any named entity not present in both sentences\n",
    "        tokens = [token.text for token in tokens if token.text not in [ent[0] for ent in named_entities]]\n",
    "        return [token for token in tokens if token not in stopwords], named_entities\n",
    "\n",
    "def wu_palmer_similarity(noun_tokens1, noun_tokens2):\n",
    "    \"\"\"Calculate the average Wu-Palmer similarity between two lists of nouns.\"\"\"\n",
    "    similarities = []\n",
    "    for noun1 in noun_tokens1:\n",
    "        for noun2 in noun_tokens2:\n",
    "            syn1 = wn.synsets(noun1)\n",
    "            syn2 = wn.synsets(noun2)\n",
    "            if syn1 and syn2:\n",
    "                similarity = wn.wup_similarity(syn1[0], syn2[0])\n",
    "                if similarity is not None:\n",
    "                    similarities.append(similarity)\n",
    "    return np.mean(similarities) if similarities else 0.0\n",
    "\n",
    "def sim2(sentence_list):\n",
    "    \"\"\"Calculate sentence-to-sentence similarity as described.\"\"\"\n",
    "    computed_similarities = []\n",
    "    \n",
    "    for T1, T2 in sentence_list:\n",
    "        nouns1, named_entities1 = preprocess_with_negation_and_entities(T1)\n",
    "        nouns2, named_entities2 = preprocess_with_negation_and_entities(T2)\n",
    "        \n",
    "        # Compute Wu-Palmer similarity for nouns\n",
    "        if not named_entities1 and not named_entities2:  # No named entities in both\n",
    "            sim_score = wu_palmer_similarity(nouns1, nouns2)\n",
    "        elif named_entities1 and named_entities2:  # Named entities present in both\n",
    "            named_entity_sim = cosine_similarity(\n",
    "                [nlp(ent[0]).vector for ent in named_entities1],\n",
    "                [nlp(ent[0]).vector for ent in named_entities2]\n",
    "            ).max()  # Get max cosine similarity\n",
    "            sim_score = 0.5 * named_entity_sim + 0.5 * wu_palmer_similarity(nouns1, nouns2)\n",
    "        else:  # Only one sentence has named entities\n",
    "            sim_score = wu_palmer_similarity(nouns1, nouns2)\n",
    "\n",
    "        computed_similarities.append(round(sim_score, 2))\n",
    "        \n",
    "    return computed_similarities\n",
    "\n",
    "### TASK 4 ###\n",
    "def compute_similarity_doc2vec(sentence_list, epochs=200):\n",
    "    \"\"\"Train a Doc2Vec model using a list of sentence pairs.\"\"\"\n",
    "\n",
    "    tagged_data = [TaggedDocument(words=preProcess(s[0]) + preProcess(s[1]), tags=[str(i)]) for i, s in enumerate(sentence_list)]\n",
    "\n",
    "    doc2vec_model = Doc2Vec(vector_size=200, alpha=0.025, min_alpha=0.00025, min_count=1, dm=1, epochs=epochs)\n",
    "    doc2vec_model.build_vocab(tagged_data)\n",
    "    doc2vec_model.train(tagged_data, total_examples=doc2vec_model.corpus_count, epochs=doc2vec_model.epochs)\n",
    "\n",
    "    computed_similarities_doc2vec = []\n",
    "    for sentence1, sentence2 in sentence_list:\n",
    "        try:\n",
    "            vec1 = doc2vec_model.infer_vector(preProcess(sentence1))\n",
    "            vec2 = doc2vec_model.infer_vector(preProcess(sentence2))\n",
    "            similarity = cosine_similarity([vec1], [vec2])[0][0]\n",
    "            computed_similarities_doc2vec.append(similarity)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing pair ({sentence1}, {sentence2}): {e}\")\n",
    "\n",
    "    return computed_similarities_doc2vec, doc2vec_model\n",
    "\n",
    "def compute_spacy_embeddings(sentence_list):\n",
    "    \"\"\"Compute SpaCy embeddings for a list of sentence pairs.\"\"\"\n",
    "    computed_similarities = []\n",
    "    for sentence1, sentence2 in sentence_list:\n",
    "        # Generate embeddings using SpaCy\n",
    "        vec1 = nlp(sentence1).vector\n",
    "        vec2 = nlp(sentence2).vector\n",
    "        # Calculate cosine similarity\n",
    "        similarity = cosine_similarity([vec1], [vec2])[0][0]\n",
    "        computed_similarities.append(similarity)\n",
    "    return computed_similarities\n",
    "\n",
    "def compute_distilbert_embeddings(sentence_list):\n",
    "    \"\"\"Compute DistilBERT embeddings for a list of sentence pairs.\"\"\"\n",
    "    computed_similarities = []\n",
    "    for sentence1, sentence2 in sentence_list:\n",
    "        inputs1 = tokenizer(sentence1, padding=True, truncation=True, return_tensors='pt')\n",
    "        inputs2 = tokenizer(sentence2, padding=True, truncation=True, return_tensors='pt')\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs1 = distilbert_model(**inputs1)\n",
    "            outputs2 = distilbert_model(**inputs2)\n",
    "\n",
    "        vec1 = outputs1.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "        vec2 = outputs2.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "\n",
    "        similarity = cosine_similarity([vec1], [vec2])[0][0]\n",
    "        computed_similarities.append(similarity)\n",
    "    return computed_similarities\n",
    "\n",
    "def compute_similarity_use(sentence_list):\n",
    "    \"\"\"Compute cosine similarity for a list of sentence pairs using the Universal Sentence Encoder.\"\"\"\n",
    "    computed_similarities = []\n",
    "    \n",
    "    for sentence1, sentence2 in sentence_list:\n",
    "        embeddings = embed([sentence1, sentence2]).numpy()\n",
    "        \n",
    "        similarity = cosine_similarity(embeddings)[0, 1]\n",
    "        computed_similarities.append(similarity)\n",
    "        \n",
    "    return computed_similarities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List lengths: 66, 66, 66\n",
      "Pearson correlation coefficient Sim1: 0.67\n",
      "Similarity between:\n",
      "'The city was noisy.'\n",
      "and\n",
      "'The forest was silent.'\n",
      "is: 0.3700\n",
      "\n",
      "Similarity between:\n",
      "'Did you finish your homework?'\n",
      "and\n",
      "'Have you completed your assignments?'\n",
      "is: 0.2600\n",
      "\n",
      "Similarity between:\n",
      "'The cat sat on the warm windowsill.'\n",
      "and\n",
      "'A cat rested on a cozy window ledge.'\n",
      "is: 0.2500\n",
      "\n",
      "Similarity between:\n",
      "'He does not like apples.'\n",
      "and\n",
      "'He dislike apples.'\n",
      "is: 0.3600\n",
      "\n",
      "Similarity between:\n",
      "'The food was delicious.'\n",
      "and\n",
      "'The meal was tasty.'\n",
      "is: 0.3800\n",
      "\n",
      "Similarity between:\n",
      "'The quick brown fox jumps over the lazy dog.'\n",
      "and\n",
      "'A quick fox leaps over a lazy hound.'\n",
      "is: 0.2800\n",
      "\n",
      "Similarity between:\n",
      "'She is not happy with the results.'\n",
      "and\n",
      "'She is sad with the results.'\n",
      "is: 0.4600\n",
      "\n",
      "Similarity between:\n",
      "'Apple Inc. released a new product.'\n",
      "and\n",
      "'Google LLC announced their latest software.'\n",
      "is: 0.4700\n",
      "\n",
      "Similarity between:\n",
      "'He did not find the answer quickly.'\n",
      "and\n",
      "'He found the answer slowly.'\n",
      "is: 0.3300\n",
      "\n",
      "Similarity between:\n",
      "'NASA announced a new space mission.'\n",
      "and\n",
      "'The European Space Agency confirmed another mission.'\n",
      "is: 0.3800\n",
      "\n",
      "Pearson correlation coefficient Sim2: 0.28\n",
      "Pearson correlation coefficient with Doc2Vec: 0.65\n",
      "Pearson correlation coefficient with SpaCy embedding: 0.47\n",
      "Pearson correlation coefficient with DistilBERT embedding: 0.84\n",
      "Pearson correlation coefficient with Universal Sentence Encoder: 0.89\n",
      "Extracted 200 sentence pairs from the train set.\n",
      "Extracted 200 sentence pairs from the test set.\n",
      "Extracted 200 sentence pairs from the dev set.\n",
      "Train Results:\n",
      "Test Results:\n",
      "Dev Results:\n",
      "Extracted 200 sentence pairs from the train set.\n",
      "Extracted 200 sentence pairs from the test set.\n",
      "Extracted 200 sentence pairs from the dev set.\n",
      "Train Results:\n",
      "  Ensemble: 0.59\n",
      "Test Results:\n",
      "  Ensemble: 0.72\n",
      "Dev Results:\n",
      "  Ensemble: 0.63\n",
      "Pearson correlation coefficient SOC-PMI-Short-Text-Similarity-: 0.67\n"
     ]
    }
   ],
   "source": [
    "sentences_stss, human_similarities = read_from_csv(\"STSS-131.csv\")\n",
    "\n",
    "runSim2 = True # Whether you want to run sim2\n",
    "\n",
    "#sim1\n",
    "computed_similarities_1 = sim1(sentences_stss)\n",
    "print(f\"List lengths: {len(sentences_stss)}, {len(human_similarities)}, {len(computed_similarities_1)}\")\n",
    "pearson_coeff_1, _ = pearsonr(human_similarities, computed_similarities_1)\n",
    "print(f\"Pearson correlation coefficient Sim1: {pearson_coeff_1:.2f}\")\n",
    "\n",
    "# Test sim2 with 10 sentence pairs\n",
    "test_pairs = [\n",
    "    (\"The city was noisy.\", \"The forest was silent.\"),\n",
    "    (\"Did you finish your homework?\", \"Have you completed your assignments?\"),\n",
    "    (\"The cat sat on the warm windowsill.\", \"A cat rested on a cozy window ledge.\"),\n",
    "    (\"He does not like apples.\", \"He dislike apples.\"),\n",
    "    (\"The food was delicious.\", \"The meal was tasty.\"),\n",
    "    (\"The quick brown fox jumps over the lazy dog.\", \"A quick fox leaps over a lazy hound.\"),\n",
    "    (\"She is not happy with the results.\", \"She is sad with the results.\"),\n",
    "    (\"Apple Inc. released a new product.\", \"Google LLC announced their latest software.\"),\n",
    "    (\"He did not find the answer quickly.\", \"He found the answer slowly.\"),\n",
    "    (\"NASA announced a new space mission.\", \"The European Space Agency confirmed another mission.\"),\n",
    "]\n",
    "computed_similarities = sim2(test_pairs)\n",
    "for (S1, S2), sim2_score in zip(test_pairs, computed_similarities):\n",
    "    print(f\"Similarity between:\\n'{S1}'\\nand\\n'{S2}'\\nis: {sim2_score:.4f}\\n\")\n",
    "\n",
    "computed_similarities_2 = sim2(sentences_stss)\n",
    "\n",
    "'''\n",
    "df = pd.DataFrame({\n",
    "    'Sentence 1': [s[0] for s in sentences_stss],\n",
    "    'Sentence 2': [s[1] for s in sentences_stss],\n",
    "    'Human Similarity': human_similarities,\n",
    "    'Computed Similarity Sim1': computed_similarities_1,\n",
    "    'Computed Similarity Sim2': computed_similarities_2\n",
    "})\n",
    "\n",
    " You can see the table in the GitHub\n",
    "df.to_excel('similarities.xlsx', index=False)\n",
    "'''\n",
    "\n",
    "pearson_coeff_2, _ = pearsonr(human_similarities, computed_similarities_2)\n",
    "\n",
    "print(f\"Pearson correlation coefficient Sim2: {pearson_coeff_2:.2f}\")\n",
    "\n",
    "# State-of-the-art embeddings:\n",
    "\n",
    "computed_similarities_doc2vec, model = compute_similarity_doc2vec(sentences_stss)\n",
    "pearson_coeff_doc2vec = pearsonr(human_similarities, computed_similarities_doc2vec)[0]\n",
    "print(f\"Pearson correlation coefficient with Doc2Vec: {pearson_coeff_doc2vec:.2f}\")\n",
    "\n",
    "computed_similarities_spacy_e = compute_spacy_embeddings(sentences_stss)\n",
    "pearson_coeff_spacy_e = pearsonr(human_similarities, computed_similarities_spacy_e)[0]\n",
    "print(f\"Pearson correlation coefficient with SpaCy embedding: {pearson_coeff_spacy_e:.2f}\")\n",
    "\n",
    "computed_similarities_distilbert_e = compute_distilbert_embeddings(sentences_stss)\n",
    "pearson_coeff_distilbert_e = pearsonr(human_similarities, computed_similarities_distilbert_e)[0]\n",
    "print(f\"Pearson correlation coefficient with DistilBERT embedding: {pearson_coeff_distilbert_e:.2f}\")\n",
    "\n",
    "computed_similarities_use = compute_similarity_use(sentences_stss)\n",
    "pearson_coeff_use, _ = pearsonr(human_similarities, computed_similarities_use)\n",
    "print(f\"Pearson correlation coefficient with Universal Sentence Encoder: {pearson_coeff_use:.2f}\")\n",
    "\n",
    "# Another dataset:\n",
    "\n",
    "ds = load_dataset(\"SemRel/SemRel2024\", \"eng\")\n",
    "datasets = [\"train\", \"test\", \"dev\"]\n",
    "\n",
    "def extract_sentences_and_labels(dataset_name):\n",
    "    '''Extract sentences and labels from a dataset from SemRel2024'''\n",
    "    \n",
    "    dataset = ds[dataset_name].shuffle(seed=42)\n",
    "    dataset = dataset.select(range(200))\n",
    "    \n",
    "    sentences = []\n",
    "    labels = []\n",
    "\n",
    "    for item in dataset:\n",
    "        sentence1 = item['sentence1'].strip()\n",
    "        sentence2 = item['sentence2'].strip()\n",
    "        label = float(item['label'])\n",
    "\n",
    "        sentences.append((sentence1, sentence2))\n",
    "        labels.append(label)\n",
    "        \n",
    "    print(f\"Extracted {len(sentences)} sentence pairs from the {dataset_name} set.\")\n",
    "    return sentences, labels \n",
    "\n",
    "results = {}\n",
    "stored_scores = {}\n",
    "\n",
    "for dataset in datasets:\n",
    "    '''Use all the previous methods for SemRel2024 datasets'''\n",
    "\n",
    "    sentences, labels = extract_sentences_and_labels(dataset)\n",
    "\n",
    "    sim1_scores = sim1(sentences)\n",
    "    sim2_scores = sim2(sentences)\n",
    "    doc2vec_scores, model = compute_similarity_doc2vec(sentences, 150)\n",
    "    spacy_scores = compute_spacy_embeddings(sentences)\n",
    "    distilbert_scores = compute_distilbert_embeddings(sentences)\n",
    "    use_scores = compute_similarity_use(sentences)\n",
    "\n",
    "    stored_scores[dataset] = {\n",
    "        'doc2vec': doc2vec_scores,\n",
    "        'spacy': spacy_scores,\n",
    "        'distilbert': distilbert_scores\n",
    "    }\n",
    "\n",
    "    # Calculate Pearson correlation coefficients\n",
    "    sim1_corr = pearsonr(sim1_scores, labels)[0]\n",
    "    sim2_corr = pearsonr(sim2_scores, labels)[0]\n",
    "    doc2vec_corr = pearsonr(doc2vec_scores, labels)[0]\n",
    "    spacy_corr = pearsonr(spacy_scores, labels)[0]\n",
    "    distilbert_corr = pearsonr(distilbert_scores, labels)[0]\n",
    "    use_corr = pearsonr(use_scores, labels)[0]\n",
    "        \n",
    "    results[dataset] = {\n",
    "        'sim1': sim1_corr,\n",
    "        'sim2': sim2_corr,\n",
    "        'doc2vec': doc2vec_corr,\n",
    "        'SpaCy': spacy_corr,\n",
    "        'DistilBERT': distilbert_corr,\n",
    "        'use': use_corr\n",
    "    }\n",
    "    \n",
    "    if (runSim2):\n",
    "\n",
    "        results[dataset] = {\n",
    "\n",
    "        }\n",
    "\n",
    "for dataset, correlations in results.items():\n",
    "    print(f\"{dataset.capitalize()} Results:\")\n",
    "    for method, corr in correlations.items():\n",
    "        print(f\"  {method}: {corr:.2f}\")\n",
    "        \n",
    "### Weighted state-of-the-art\n",
    "weights = [0.25, 0.25, 0.5]\n",
    "\n",
    "for dataset in datasets:\n",
    "    '''Use all the previous methods for SemRel2024 datasets'''\n",
    "    sentences, labels = extract_sentences_and_labels(dataset)\n",
    "    \n",
    "    doc2vec_scores = stored_scores[dataset]['doc2vec']\n",
    "    spacy_scores = stored_scores[dataset]['spacy']\n",
    "    distilbert_scores = stored_scores[dataset]['distilbert']\n",
    "    \n",
    "    ensemble_scores = [\n",
    "        sum(w * sim for w, sim in zip(weights, similarities))\n",
    "        for similarities in zip(doc2vec_scores, spacy_scores, distilbert_scores)\n",
    "    ]\n",
    "    ensemble_corr = pearsonr(ensemble_scores, labels)[0]\n",
    "    results[dataset] = {\n",
    "        'Ensemble': ensemble_corr\n",
    "    }\n",
    "    \n",
    "for dataset, correlations in results.items():\n",
    "    print(f\"{dataset.capitalize()} Results:\")\n",
    "    for method, corr in correlations.items():\n",
    "        print(f\"  {method}: {corr:.2f}\")\n",
    "        \n",
    "# Similarity from GitHub SOC-PMI-Short-Text-Similarity\n",
    "\n",
    "SOC_similarities = []\n",
    "for S1, S2 in sentences_stss:\n",
    "    sim_score = similarity(S1, S2) # Call the similarity from the provided repository\n",
    "    SOC_similarities.append(sim_score)\n",
    "    \n",
    "SOC_coefficient = pearsonr(SOC_similarities, human_similarities)[0]\n",
    "print(f\"Pearson correlation coefficient SOC-PMI-Short-Text-Similarity-: {pearson_coeff_1:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
