{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5783551-d5ec-4351-8df4-ac4756f4379d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.stats import pearsonr\n",
    "import spacy\n",
    "from itertools import product\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a053f867",
   "metadata": {},
   "source": [
    "### Assignment 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24b82757-638d-48f0-bcf4-cb3c9c8072fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = list(set(nltk.corpus.stopwords.words('english')))\n",
    "\n",
    "def preProcess(sentence):\n",
    "    \"\"\"Tokenize, remove stopwords, and clean the sentence.\"\"\"\n",
    "    words = word_tokenize(sentence)\n",
    "    words = [word.lower() for word in words if word.isalpha() and word not in stopwords] \n",
    "    return words\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character for lemmatization with WordNet.\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wn.ADJ, \"N\": wn.NOUN, \"V\": wn.VERB, \"R\": wn.ADV}\n",
    "    return tag_dict.get(tag, wn.NOUN)  \n",
    "\n",
    "def word_similarity(w1, w2):\n",
    "    \"\"\"Calculate similarity between two words only if they share the same POS.\"\"\"\n",
    "    pos1 = get_wordnet_pos(w1)\n",
    "    pos2 = get_wordnet_pos(w2)\n",
    "\n",
    "    synsets1 = wn.synsets(w1, pos=pos1)\n",
    "    synsets2 = wn.synsets(w2, pos=pos2)\n",
    "    \n",
    "    if synsets1 and synsets2:\n",
    "        S1 = synsets1[0]  \n",
    "        S2 = synsets2[0]  \n",
    "        try:\n",
    "            similarity = S1.wup_similarity(S2)\n",
    "            if similarity:\n",
    "                return round(similarity, 2)\n",
    "        except nltk.corpus.reader.wordnet.WordNetError:\n",
    "            return 0\n",
    "    return 0\n",
    "\n",
    "def sim1(T1, T2):\n",
    "    \"\"\"Calculate sentence-to-sentence similarity using TF-IDF and WordNet similarity.\"\"\"\n",
    "    words1 = preProcess(T1)\n",
    "    words2 = preProcess(T2)\n",
    "\n",
    "    tf = TfidfVectorizer(use_idf=True)\n",
    "    tf.fit_transform([' '.join(words1), ' '.join(words2)])\n",
    "    \n",
    "    Idf = dict(zip(tf.get_feature_names_out(), tf.idf_))\n",
    "    \n",
    "    Sim_score1 = 0\n",
    "    Sim_score2 = 0\n",
    "\n",
    "    for w1 in words1:\n",
    "        Max = 0\n",
    "        for w2 in words2:\n",
    "            score = word_similarity(w1, w2)\n",
    "            if Max < score:\n",
    "                Max = score\n",
    "        Sim_score1 += Max * Idf.get(w1, 0)\n",
    "    Sim_score1 /= sum([Idf.get(w1, 0) for w1 in words1])\n",
    "\n",
    "    for w2 in words2:\n",
    "        Max = 0\n",
    "        for w1 in words1:\n",
    "            score = word_similarity(w1, w2)\n",
    "            if Max < score:\n",
    "                Max = score\n",
    "        Sim_score2 += Max * Idf.get(w2, 0)\n",
    "    Sim_score2 /= sum([Idf.get(w2, 0) for w2 in words2])\n",
    "\n",
    "    Sim = (Sim_score1 + Sim_score2) / 2\n",
    "    \n",
    "    return round(Sim, 2)\n",
    "\n",
    "def read_from_csv(file_path):\n",
    "    '''Read sentences and the corresponding similarity scores from a csv file'''\n",
    "    sentences = []\n",
    "    scores = []\n",
    "    \n",
    "    with open(file_path, mode='r', newline='', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file, delimiter=';')\n",
    "        next(reader) # Skip the header\n",
    "        for row in reader:\n",
    "            if len(row) == 3:\n",
    "                sentence1, sentence2, score = row\n",
    "                sentences.append((sentence1.strip(), sentence2.strip()))  # Append tuple of sentences\n",
    "                scores.append(float(score.strip()))\n",
    "    return sentences, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f5c5159-255c-4369-8640-5cc2146b449a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List lengths: 66, 66, 66\n",
      "Pearson correlation coefficient Sim1: 0.55\n"
     ]
    }
   ],
   "source": [
    "sentences, human_similarities = read_from_csv(\"STSS-131.csv\");\n",
    "\n",
    "computed_similarities_1 = []\n",
    "for sentence1, sentence2 in sentences:\n",
    "    score = sim1(sentence1, sentence2)\n",
    "    computed_similarities_1.append(score)\n",
    "    \n",
    "print(f\"List lengths: {len(sentences)}, {len(human_similarities)}, {len(computed_similarities_1)}\")\n",
    "\n",
    "pearson_coeff_1, p_value = pearsonr(human_similarities, computed_similarities_1)\n",
    "\n",
    "print(f\"Pearson correlation coefficient Sim1: {pearson_coeff_1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e585400",
   "metadata": {},
   "source": [
    "### Assignment 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1e561d7-e09e-4279-9638-6fe04739b82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Pair 1:\n",
      "S1: The city was noisy.\n",
      "S2: The forest was silent.\n",
      "Similarity (Sim2): 0.13333333333333333\n",
      "\n",
      "Sentence Pair 2:\n",
      "S1: Did you finish your homework?\n",
      "S2: Have you completed your assignments?\n",
      "Similarity (Sim2): 0.7\n",
      "\n",
      "Sentence Pair 3:\n",
      "S1: The cat sat on the warm windowsill.\n",
      "S2: A cat rested on a cozy window ledge.\n",
      "Similarity (Sim2): 0.763157894736842\n",
      "\n",
      "Sentence Pair 4:\n",
      "S1: He does not like apples.\n",
      "S2: He dislike apples.\n",
      "Similarity (Sim2): 0.7316017316017316\n",
      "\n",
      "Sentence Pair 5:\n",
      "S1: The food was delicious.\n",
      "S2: The meal was tasty.\n",
      "Similarity (Sim2): 0.8333333333333334\n",
      "\n",
      "Sentence Pair 6:\n",
      "S1: The quick brown fox jumps over the lazy dog.\n",
      "S2: A quick fox leaps over a lazy hound.\n",
      "Similarity (Sim2): 0.7261904761904763\n",
      "\n",
      "Sentence Pair 7:\n",
      "S1: She is not happy with the results.\n",
      "S2: She is sad with the results.\n",
      "Similarity (Sim2): 1.0\n",
      "\n",
      "Sentence Pair 8:\n",
      "S1: Apple Inc. released a new product.\n",
      "S2: Google LLC announced their latest software.\n",
      "Similarity (Sim2): 0.269919322265519\n",
      "\n",
      "Sentence Pair 9:\n",
      "S1: He did not find the answer quickly.\n",
      "S2: He found the answer slowly.\n",
      "Similarity (Sim2): 1.0\n",
      "\n",
      "Sentence Pair 10:\n",
      "S1: NASA announced a new space mission.\n",
      "S2: The European Space Agency confirmed another mission.\n",
      "Similarity (Sim2): 0.525150426559978\n",
      "\n"
     ]
    }
   ],
   "source": [
    "negations = {\"not\", \"no\", \"never\", \"n't\"}\n",
    "\n",
    "# Change words to noun if possible \n",
    "def to_noun_form(tokens):\n",
    "    noun_tokens = []\n",
    "    for token, pos in pos_tag(tokens):\n",
    "            if pos.startswith('VB') or pos.startswith('JJ') or pos.startswith('RB'):\n",
    "                synsets = wn.synsets(token)\n",
    "                noun_form = token\n",
    "                for s in synsets:\n",
    "                    for lemma in s.lemmas():\n",
    "                        noun_synsets = wn.synsets(lemma.name(), wn.NOUN)\n",
    "                        if noun_synsets:\n",
    "                            noun_form = lemma.name()\n",
    "                            break\n",
    "                    if noun_form != token:\n",
    "                        break\n",
    "            else:\n",
    "                noun_synsets = wn.synsets(token, wn.NOUN)\n",
    "                noun_tokens.append(noun_synsets[0].lemmas()[0].name() if noun_synsets else token)\n",
    "    return noun_tokens\n",
    "\n",
    "# Handle negation by finding antonyms of adjectives/adverbs\n",
    "def handle_negation(tokens):\n",
    "    modified_tokens = []\n",
    "    skip_next = False\n",
    "    negated_adverbs = []\n",
    "    pos_tags = pos_tag(tokens)\n",
    "    for i, (token, pos) in enumerate(pos_tags):\n",
    "        if token.lower() in negations:\n",
    "            if i + 1 < len(pos_tags):\n",
    "                next_token, next_pos = pos_tags[i + 1]\n",
    "                if next_pos.startswith(\"JJ\") or next_pos.startswith(\"RB\"):\n",
    "                    antonym = get_antonym(next_token)\n",
    "                    negated_adverbs.append(antonym if antonym else next_token)\n",
    "                    skip_next = True\n",
    "                else:\n",
    "                    modified_tokens.append(token)\n",
    "        elif skip_next:\n",
    "            skip_next = False\n",
    "        else:\n",
    "            modified_tokens.append(token)\n",
    "    \n",
    "    modified_tokens.extend(negated_adverbs)\n",
    "    return modified_tokens\n",
    "\n",
    "def get_antonym(token):\n",
    "    for synset in wn.synsets(token):\n",
    "        for lemma in synset.lemmas():\n",
    "            if lemma.antonyms():\n",
    "                return lemma.antonyms()[0].name()\n",
    "    return None\n",
    "\n",
    "# Clean the tokens, removes stopwords and unnecessary characters\n",
    "def clean_tokens(tokens):\n",
    "    return [token for token in tokens if token.isalnum() and token.lower() not in stopwords]\n",
    "\n",
    "# Calculate Wu-Palmer simlarity for nouns\n",
    "def wu_palmer_similarity(nouns1, nouns2):\n",
    "    similarities = []\n",
    "    for n1 in nouns1:\n",
    "        synset1 = wn.synsets(n1, wn.NOUN)\n",
    "        if not synset1:  \n",
    "            continue\n",
    "        max_similarity = 0\n",
    "        for n2 in nouns2:\n",
    "            synset2 = wn.synsets(n2, wn.NOUN)\n",
    "            if not synset2:  \n",
    "                continue\n",
    "            similarity = synset1[0].wup_similarity(synset2[0]) or 0\n",
    "            max_similarity = max(max_similarity, similarity)\n",
    "        similarities.append(max_similarity)\n",
    "    return sum(similarities) / len(similarities) if similarities else 0\n",
    "\n",
    "# Named entity cosine similarity\n",
    "def entity_similarity(named_entities1, named_entities2):\n",
    "    if not (named_entities1 and named_entities2):\n",
    "        return 0\n",
    "    return max(ent1.similarity(ent2) for ent1 in named_entities1 for ent2 in named_entities2)\n",
    "\n",
    "# Calculate Sim2\n",
    "def sim2(sentence1, sentence2, alpha=0.5):\n",
    "    doc1, doc2 = nlp(sentence1), nlp(sentence2)\n",
    "    named_entities1, named_entities2 = [ent for ent in doc1.ents], [ent for ent in doc2.ents]\n",
    "    \n",
    "    tokens1, tokens2 = word_tokenize(sentence1), word_tokenize(sentence2)\n",
    "    tokens1, tokens2 = handle_negation(tokens1), handle_negation(tokens2)\n",
    "    tokens1, tokens2 = clean_tokens(to_noun_form(tokens1)), clean_tokens(to_noun_form(tokens2))\n",
    "    \n",
    "    if named_entities1 and named_entities2:\n",
    "        entity_sim = entity_similarity(named_entities1, named_entities2)\n",
    "        semantic_sim = wu_palmer_similarity(tokens1, tokens2)\n",
    "        return alpha * entity_sim + (1 - alpha) * semantic_sim\n",
    "    else:\n",
    "        return wu_palmer_similarity(tokens1, tokens2)\n",
    "\n",
    "\n",
    "# Test with 10 sentence pairs\n",
    "test_pairs = [\n",
    "    (\"The city was noisy.\", \"The forest was silent.\"),\n",
    "    (\"Did you finish your homework?\", \"Have you completed your assignments?\"),\n",
    "    (\"The cat sat on the warm windowsill.\", \"A cat rested on a cozy window ledge.\"),\n",
    "    (\"He does not like apples.\", \"He dislike apples.\"),\n",
    "    (\"The food was delicious.\", \"The meal was tasty.\"),\n",
    "    (\"The quick brown fox jumps over the lazy dog.\", \"A quick fox leaps over a lazy hound.\"),\n",
    "    (\"She is not happy with the results.\", \"She is sad with the results.\"),\n",
    "    (\"Apple Inc. released a new product.\", \"Google LLC announced their latest software.\"),\n",
    "    (\"He did not find the answer quickly.\", \"He found the answer slowly.\"),\n",
    "    (\"NASA announced a new space mission.\", \"The European Space Agency confirmed another mission.\"),\n",
    "]\n",
    "\n",
    "for i, (s1, s2) in enumerate(test_pairs):\n",
    "    similarity = sim2(s1, s2)\n",
    "    print(f\"Sentence Pair {i+1}:\")\n",
    "    print(f\"S1: {s1}\")\n",
    "    print(f\"S2: {s2}\")\n",
    "    print(f\"Similarity (Sim2): {similarity}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f034b25e",
   "metadata": {},
   "source": [
    "### Assignment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e04ca65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient Sim1: 0.55\n",
      "Pearson correlation coefficient Sim2: 0.31\n"
     ]
    }
   ],
   "source": [
    "computed_similarities_2 = []\n",
    "for sentence1, sentence2 in sentences:\n",
    "    score = sim2(sentence1, sentence2)\n",
    "    computed_similarities_2.append(score)\n",
    "    \n",
    "df = pd.DataFrame({\n",
    "    'Sentence 1': [s[0] for s in sentences],\n",
    "    'Sentence 2': [s[1] for s in sentences],\n",
    "    'Human Similarity': human_similarities,\n",
    "    'Computed Similarity Sim1': computed_similarities_1,\n",
    "    'Computed Similarity Sim2': computed_similarities_2\n",
    "})\n",
    "\n",
    "#'''You can see the table in the GitHub'''\n",
    "#df.to_excel('similarities.xlsx', index=False)\n",
    "\n",
    "pearson_coeff_2, p_value = pearsonr(human_similarities, computed_similarities_2)\n",
    "\n",
    "print(f\"Pearson correlation coefficient Sim1: {pearson_coeff_1:.2f}\")\n",
    "print(f\"Pearson correlation coefficient Sim2: {pearson_coeff_2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d731f753",
   "metadata": {},
   "source": [
    "The pearson correlation yields a worse answer. Meaning that the method of turning everything to nouns, the antonym preprocessing and using the named-entities preprocessing give us worse results than with just the preprocesses used in task 1. This may be due to the added complexity, which weren't accounted for in the human similarity judgments.\n",
    "The preprocessing methods may also lead to a loss of important semantic information. Named entities are supposed to help by focusing on specific terms, but if they are not well aligned with the context of the sentences, they may add more noise rather than clarity. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
